{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "380dcf4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import os\n",
    "import h5py\n",
    "import pickle  # TODO or use h5py instead?\n",
    "import trimesh\n",
    "\n",
    "import config as cfg\n",
    "import dataset.augmentation as Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4a7ca887",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DatasetModelnet40(Dataset):\n",
    "    \n",
    "    def __init__(self, split, noise_type):\n",
    "        dataset_path = cfg.M40_PATH\n",
    "        categories = np.arange(20) if split in [\"train\", \"val\"] else np.arange(20, 40)\n",
    "        split = \"test\" if split == \"val\" else split  # ModelNet40 has no validation set - use cat 0-19 with test set\n",
    "\n",
    "        self.samples, self.labels = self.get_samples(dataset_path, split, categories)\n",
    "        self.transforms = self.get_transforms(split, noise_type)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sample = {'points': self.samples[item, :, :], 'label': self.labels[item], 'idx': np.array(item, dtype=np.int32)}\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample\n",
    "\n",
    "    def get_transforms(self, split, noise_type):\n",
    "        # prepare augmentations\n",
    "        if noise_type == \"clean\":\n",
    "            # 1-1 correspondence for each point (resample first before splitting), no noise\n",
    "            if split == \"train\":\n",
    "                transforms = [Transforms.Resampler(1024),\n",
    "                              Transforms.SplitSourceRef(),\n",
    "                              Transforms.Scale(), Transforms.Shear(), Transforms.Mirror(),\n",
    "                              Transforms.RandomTransformSE3_euler(),\n",
    "                              Transforms.ShufflePoints()]\n",
    "            else:\n",
    "                transforms = [Transforms.SetDeterministic(),\n",
    "                              Transforms.FixedResampler(1024),\n",
    "                              Transforms.SplitSourceRef(),\n",
    "                              Transforms.RandomTransformSE3_euler(),\n",
    "                              Transforms.ShufflePoints()]\n",
    "        elif noise_type == \"jitter\":\n",
    "            # Points randomly sampled (might not have perfect correspondence), gaussian noise to position\n",
    "            if split == \"train\":\n",
    "                transforms = [Transforms.SplitSourceRef(),\n",
    "                              Transforms.Scale(), Transforms.Shear(), Transforms.Mirror(),\n",
    "                              Transforms.RandomTransformSE3_euler(),\n",
    "                              Transforms.Resampler(1024),\n",
    "                              Transforms.RandomJitter(),\n",
    "                              Transforms.ShufflePoints()]\n",
    "            else:\n",
    "                transforms = [Transforms.SetDeterministic(),\n",
    "                              Transforms.SplitSourceRef(),\n",
    "                              Transforms.RandomTransformSE3_euler(),\n",
    "                              Transforms.Resampler(1024),\n",
    "                              Transforms.RandomJitter(),\n",
    "                              Transforms.ShufflePoints()]\n",
    "        else:\n",
    "            raise ValueError(f\"Noise type {noise_type} not supported for ModelNet40.\")\n",
    "\n",
    "        return torchvision.transforms.Compose(transforms)\n",
    "\n",
    "    def get_samples(self, dataset_path, split, categories):\n",
    "        filelist = [os.path.join(dataset_path, file.strip().split(\"/\")[-1])\n",
    "                   for file in open(os.path.join(dataset_path, f'{split}_files.txt'))]\n",
    "\n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        for fi, fname in enumerate(filelist):\n",
    "            f = h5py.File(fname, mode='r')\n",
    "            data = np.concatenate([f['data'][:], f['normal'][:]], axis=-1)\n",
    "            labels = f['label'][:].flatten().astype(np.int64)\n",
    "\n",
    "            if categories is not None:  # Filter out unwanted categories\n",
    "                mask = np.isin(labels, categories).flatten()\n",
    "                data = data[mask, ...]\n",
    "                labels = labels[mask, ...]\n",
    "\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "        all_data = np.concatenate(all_data, axis=0)\n",
    "        all_labels = np.concatenate(all_labels, axis=0)\n",
    "        return all_data, all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "25d8cf06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'label': 7, 'idx': array(0, dtype=int32), 'points_raw': array([[-0.28381357,  0.03711117, -0.32101122,  0.615526  ,  0.492254  ,\n",
      "        -0.615478  ],\n",
      "       [ 0.5578954 , -0.41320965, -0.15411651, -0.270454  ,  0.923956  ,\n",
      "         0.27048   ],\n",
      "       [-0.35169974,  0.20326908, -0.42259684,  0.653771  , -0.381099  ,\n",
      "        -0.653717  ],\n",
      "       ...,\n",
      "       [ 0.38058695, -0.20426388,  0.4324199 ,  0.707123  ,  0.0021871 ,\n",
      "        -0.707087  ],\n",
      "       [ 0.28581825, -0.44051182,  0.34911266, -0.00156324,  0.999997  ,\n",
      "         0.00156325],\n",
      "       [-0.25075912, -0.10793268, -0.22646542, -0.0033314 ,  0.999989  ,\n",
      "         0.00333113]], dtype=float32), 'points_src': array([[ 0.08782253,  0.14693572,  0.48750055,  0.95640266,  0.11370768,\n",
      "         0.26900512],\n",
      "       [ 0.38300854,  0.1162279 ,  0.21228456, -0.9563935 , -0.11376374,\n",
      "        -0.26901668],\n",
      "       [ 0.4660697 ,  0.68940806,  0.6999218 , -0.13051961,  0.9519471 ,\n",
      "         0.27705857],\n",
      "       ...,\n",
      "       [ 0.60018444,  0.19838978,  0.63588274,  0.9476484 ,  0.15376496,\n",
      "         0.2798541 ],\n",
      "       [ 0.5512263 ,  0.61466795,  0.24997616,  0.9555863 ,  0.11782862,\n",
      "         0.27013305],\n",
      "       [ 0.80365276,  0.49683332,  0.80273527,  0.23845331, -0.93882847,\n",
      "        -0.24847881]], dtype=float32), 'points_ref': array([[ 0.38757414, -0.0371165 , -0.12276434, -0.00371638, -0.999985  ,\n",
      "         0.00399277],\n",
      "       [ 0.28581825, -0.44051182,  0.34911266, -0.00156324,  0.999997  ,\n",
      "         0.00156325],\n",
      "       [ 0.05670599, -0.4481898 ,  0.1044283 , -0.661352  , -0.382449  ,\n",
      "         0.645249  ],\n",
      "       ...,\n",
      "       [ 0.3634836 , -0.0284082 ,  0.59006184, -0.707167  , -0.00227654,\n",
      "         0.707042  ],\n",
      "       [-0.61588293, -0.06138062, -0.212332  ,  0.580283  , -0.194051  ,\n",
      "         0.790958  ],\n",
      "       [ 0.29722714,  0.1633073 ,  0.61401516,  0.0458514 , -0.998465  ,\n",
      "         0.0310789 ]], dtype=float32), 'scale': array([0.89122159, 1.04122995, 0.6860302 ]), 'transform_gt': array([[ 0.83645654,  0.28715482, -0.46677896, -0.2385338 ],\n",
      "       [-0.18434381,  0.949529  ,  0.25379518, -0.38471577],\n",
      "       [ 0.5160987 , -0.12624082,  0.84717494, -0.4088592 ]],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset = DatasetModelnet40(split = \"train\", noise_type=\"clean\")\n",
    "    #print(len(dataset))\n",
    "    print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aed63fd0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
