{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79754eb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(10)\n",
    "import torch\n",
    "torch.manual_seed(10)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "torch.set_default_dtype(torch.float32)\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from prefetch_generator import BackgroundGenerator\n",
    "import argparse\n",
    "\n",
    "import sys\n",
    "sys.path.append(os.path.dirname(os.getcwd()).replace(\"/registration\", \"\"))\n",
    "from environment import environment as env\n",
    "from environment import transformations as tra\n",
    "from environment.buffer import Buffer\n",
    "from registration.model import Agent\n",
    "import registration.model as util_model\n",
    "import utility.metrics as metrics\n",
    "from utility.logger import Logger\n",
    "from dataset.dataset_custom import CustomDataset\n",
    "import config as cfg\n",
    "import easydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "69e20631",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c055fa57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(agent, logger, dataset, noise_type, epochs, lr, lr_step, alpha, model_path, reward_mode=\"\"):\n",
    "    optimizer = torch.optim.Adam(agent.parameters(), lr=lr, amsgrad=True)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, lr_step, 0.5)\n",
    "\n",
    "    Dataset = CustomDataset if dataset == 'Custom' else None\n",
    "    train_dataset = Dataset(\"train\", noise_type)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True)\n",
    "    val_dataset = Dataset(\"val\", noise_type)\n",
    "    val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
    "    test_dataset = Dataset(\"test\", noise_type)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=cfg.BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    RANDOM_STATE = np.random.get_state()  # otherwise loader produces deterministic samples after iter 1\n",
    "    losses_bc, losses_ppo, train_rewards, final_rewards = [], [], [], []\n",
    "    episode = 0  # for loss logging (not using epoch)\n",
    "    best_chamfer = np.infty\n",
    "\n",
    "    buffer = Buffer()\n",
    "    buffer.start_trajectory()\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch}\")\n",
    "\n",
    "        # -- train\n",
    "        agent.train()\n",
    "        np.random.set_state(RANDOM_STATE)\n",
    "\n",
    "        progress = tqdm(BackgroundGenerator(train_loader), total=len(train_loader))\n",
    "        for data in progress:\n",
    "            with torch.no_grad():\n",
    "                # per sample, generate a full trajectory\n",
    "                source, target, pose_source, pose_target = env.init(data)\n",
    "\n",
    "                if cfg.DISENTANGLED:\n",
    "                    pose_target = tra.to_disentangled(pose_target, source)\n",
    "                current_source = source\n",
    "                if reward_mode == \"goal\":\n",
    "                    reward = env.reward_goal(pose_source, pose_target)\n",
    "                elif reward_mode == \"step\":\n",
    "                    gt_pcd_source = tra.apply_trafo(current_source, pose_target, disentangled=cfg.DISENTANGLED)\n",
    "                    _, prev_chamfer = env.reward_step(current_source, gt_pcd_source)\n",
    "\n",
    "                # STAGE 1: generate trajectories\n",
    "                for step in range(cfg.ITER_TRAIN):\n",
    "                    # expert prediction\n",
    "                    expert_action = env.expert(pose_source, pose_target, mode=cfg.EXPERT_MODE)\n",
    "\n",
    "                    # student prediction -- stochastic policy\n",
    "                    state_emb, action_logit, state_value, _ = agent(current_source, target)\n",
    "\n",
    "                    action = util_model.action_from_logits(action_logit, deterministic=False)\n",
    "                    action_logprob, action_entropy = util_model.action_stats(action_logit, action)\n",
    "\n",
    "                    # step environment and get reward\n",
    "                    new_source, pose_source = env.step(source, action, pose_source, cfg.DISENTANGLED)\n",
    "                    if reward_mode == \"goal\":\n",
    "                        reward = env.reward_goal(pose_source, pose_target)\n",
    "                    elif reward_mode == \"step\":\n",
    "                        reward, prev_chamfer = env.reward_step(new_source, gt_pcd_source, prev_chamfer)\n",
    "                    else:\n",
    "                        reward = torch.zeros((pose_source.shape[0], 1, 1)).to(DEVICE)\n",
    "\n",
    "                    # log trajectory\n",
    "                    buffer.log_step([current_source, target], state_value, reward,\n",
    "                                    expert_action,\n",
    "                                    action, action_logit, action_logprob)\n",
    "\n",
    "                    current_source = new_source\n",
    "\n",
    "                    train_rewards.append(reward.view(-1))\n",
    "                final_rewards.append(reward.view(-1))\n",
    "\n",
    "            if len(buffer) == cfg.NUM_TRAJ:\n",
    "                # STAGE 2: policy (and value estimator) update using BC (and PPO)\n",
    "\n",
    "                # convert buffer to tensor of samples (also computes return and advantage over trajectories)\n",
    "                samples = buffer.get_samples()\n",
    "                ppo_dataset = torch.utils.data.TensorDataset(*samples)\n",
    "                ppo_loader = torch.utils.data.DataLoader(ppo_dataset, batch_size=cfg.BATCH_SIZE, shuffle=True,\n",
    "                                                         drop_last=False)\n",
    "\n",
    "                # sample batches from buffer and update\n",
    "                for batch in ppo_loader:\n",
    "                    sources, targets, \\\n",
    "                    expert_actions, state_values, \\\n",
    "                    actions, action_logits, action_logprobs, \\\n",
    "                    returns, advantages = batch\n",
    "\n",
    "                    # -- predict using current policy\n",
    "                    new_state_emb, new_action_logit, new_values, _ = agent(sources, targets)\n",
    "                    new_action_logprob, new_action_entropy = util_model.action_stats(new_action_logit, actions)\n",
    "\n",
    "                    # -- clone term\n",
    "                    loss_translation = F.cross_entropy(new_action_logit[0].view(-1, 11, 1, 1, 1),\n",
    "                                                       expert_actions[:, 0].reshape(-1, 1, 1, 1))\n",
    "                    loss_rotation = F.cross_entropy(new_action_logit[1].view(-1, 11, 1, 1, 1),\n",
    "                                                    expert_actions[:, 1].reshape(-1, 1, 1, 1))\n",
    "                    clone_loss = (loss_translation + loss_rotation) / 2\n",
    "\n",
    "                    if alpha > 0:\n",
    "                        # -- policy term\n",
    "                        # ratio: lp > prev_lp --> probability of selecting that action increased\n",
    "                        ratio = torch.exp(new_action_logprob - action_logprobs).view(-1, 6)\n",
    "                        policy_loss = -torch.min(ratio * advantages.repeat(1, 6),\n",
    "                                                 ratio.clamp(1 - cfg.CLIP_EPS,\n",
    "                                                             1 + cfg.CLIP_EPS) * advantages.repeat(1, 6)).mean()\n",
    "\n",
    "                        # -- value term\n",
    "                        value_loss = (new_values.view(-1, 1) - returns).pow(2)\n",
    "                        if cfg.CLIP_VALUE:\n",
    "                            values_clipped = state_values + (new_values - state_values)\\\n",
    "                                .clamp(-cfg.CLIP_EPS, cfg.CLIP_EPS)\n",
    "                            losses_v_clipped = (values_clipped.view(-1, 1) - returns).pow(2)\n",
    "                            value_loss = torch.max(value_loss, losses_v_clipped)\n",
    "                        value_loss = value_loss.mean()\n",
    "\n",
    "                        # -- entropy term\n",
    "                        entropy_loss = new_action_entropy.mean()\n",
    "\n",
    "                    # -- update\n",
    "                    optimizer.zero_grad()\n",
    "                    loss = clone_loss\n",
    "                    losses_bc.append(clone_loss.item())\n",
    "                    if alpha > 0:\n",
    "                        ppo_loss = policy_loss + value_loss * cfg.C_VALUE - entropy_loss * cfg.C_ENTROPY\n",
    "                        loss += ppo_loss * alpha\n",
    "                        losses_ppo.append(ppo_loss.item())\n",
    "                    loss.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # logging\n",
    "                if alpha > 0:\n",
    "                    logger.record(\"train/ppo\", np.mean(losses_ppo))\n",
    "                logger.record(\"train/bc\", np.mean(losses_bc))\n",
    "                logger.record(\"train/reward\", float(torch.cat(train_rewards, dim=0).mean()))\n",
    "                logger.record(\"train/final_reward\", float(torch.cat(final_rewards, dim=0).mean()))\n",
    "                logger.dump(step=episode)\n",
    "\n",
    "                # reset\n",
    "                losses_bc, losses_ppo, train_rewards, final_rewards = [], [], [], []\n",
    "                buffer.clear()\n",
    "                episode += 1\n",
    "\n",
    "            buffer.start_trajectory()\n",
    "        scheduler.step()\n",
    "        RANDOM_STATE = np.random.get_state()  # evaluation sets seeds again -- keep random state of the training stage\n",
    "\n",
    "        # -- test\n",
    "        if val_loader is not None:\n",
    "            chamfer_val = evaluate(agent, logger, val_loader, prefix='val')\n",
    "        if test_loader is not None:\n",
    "            chamfer_test = evaluate(agent, logger, test_loader)\n",
    "\n",
    "        if chamfer_test <= best_chamfer:\n",
    "            print(f\"new best: {chamfer_test}\")\n",
    "            best_chamfer = chamfer_test\n",
    "            infos = {\n",
    "                'epoch': epoch,\n",
    "                'optimizer_state_dict': optimizer.state_dict()\n",
    "            }\n",
    "            util_model.save(agent, f\"{model_path}.zip\", infos)\n",
    "        logger.dump(step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "74846c26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(agent, logger, loader, prefix='test'):\n",
    "    agent.eval()\n",
    "    progress = tqdm(BackgroundGenerator(loader), total=len(loader))\n",
    "    predictions = []\n",
    "    val_losses = []\n",
    "    with torch.no_grad():\n",
    "        for data in progress:\n",
    "            source, target, pose_source, pose_target = env.init(data)\n",
    "            if cfg.DISENTANGLED:\n",
    "                pose_target = tra.to_disentangled(pose_target, source)\n",
    "\n",
    "            current_source = source\n",
    "            for step in range(cfg.ITER_EVAL):\n",
    "                expert_action = env.expert(pose_source, pose_target, mode=cfg.EXPERT_MODE)\n",
    "\n",
    "                state_emb, action_logit, _, _ = agent(current_source, target)\n",
    "                action = util_model.action_from_logits(action_logit, deterministic=True)\n",
    "\n",
    "                loss_translation = F.cross_entropy(action_logit[0].view(-1, 11, 1, 1, 1),\n",
    "                                                   expert_action[:, 0].reshape(-1, 1, 1, 1))\n",
    "                loss_rotation = F.cross_entropy(action_logit[1].view(-1, 11, 1, 1, 1),\n",
    "                                                expert_action[:, 1].reshape(-1, 1, 1, 1))\n",
    "                val_losses.append((loss_translation + loss_rotation).item()/2)\n",
    "\n",
    "                current_source, pose_source = env.step(source, action, pose_source, cfg.DISENTANGLED)\n",
    "            if cfg.DISENTANGLED:\n",
    "                pose_source = tra.to_global(pose_source, source)\n",
    "            predictions.append(pose_source)\n",
    "\n",
    "    predictions = torch.cat(predictions)\n",
    "    _, summary_metrics = metrics.compute_stats(predictions, data_loader=loader)\n",
    "\n",
    "#     # log test metrics\n",
    "#     if isinstance(loader.dataset, DatasetLinemod):\n",
    "#         logger.record(f\"{prefix}/add\", summary_metrics['add'])\n",
    "#         logger.record(f\"{prefix}/adi\", summary_metrics['adi'])\n",
    "#         return summary_metrics['add']\n",
    "#     else:\n",
    "    logger.record(f\"{prefix}/mae-r\", summary_metrics['r_mae'])\n",
    "    logger.record(f\"{prefix}/mae-t\", summary_metrics['t_mae'])\n",
    "    logger.record(f\"{prefix}/iso-r\", summary_metrics['r_iso'])\n",
    "    logger.record(f\"{prefix}/iso-t\", summary_metrics['t_iso'])\n",
    "    logger.record(f\"{prefix}/chamfer\", summary_metrics['chamfer_dist'])\n",
    "    logger.record(f\"{prefix}/adi-auc\", summary_metrics['adi_auc10'] * 100)\n",
    "    return summary_metrics['chamfer_dist']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4e2f4e16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training: dataset 'Custom' - mode 'ilrl' - alpha=0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.02it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.08it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best: 44.09375762939453\n",
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.15it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.09it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best: 26.737964630126953\n",
      "Epoch 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.10it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best: 3.0416855812072754\n",
      "Epoch 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.35s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.40it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  9.77it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best: 0.09499603509902954\n",
      "Epoch 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.01it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.91it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best: 0.05859482288360596\n",
      "Epoch 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.08it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best: 0.02483583614230156\n",
      "Epoch 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.11it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.35s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.15it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new best: 0.010804089717566967\n",
      "Epoch 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.12it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.22it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.17it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.13it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.61it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.27it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.13it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.21it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.11it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.25it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  4.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.21it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.06it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.94it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.96it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.01it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  6.00it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.27it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.22it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.38it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.28it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.12it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.99it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.27it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.06it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.37it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.12it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.03it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.33it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.94it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.95it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.11it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.08it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.95it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.11it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.98it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.07it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.09it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.09it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.34it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.02it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.33s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.10it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.97it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.02it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.01it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.33s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.96it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.93it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.04it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.04it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.00it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.11it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.32s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.97it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.17it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.36it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.09it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.01it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.35it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.07it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:06<00:00,  1.33s/it]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.94it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.08it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.32it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 11.98it/s]\n",
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5/5 [00:04<00:00,  1.05it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00,  5.31it/s]\n",
      "100%|██████████| 1/1 [00:00<00:00, 12.07it/s]\n",
      "                                     \r"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "\n",
    "    args = easydict.EasyDict({'mode': 'ilrl',\n",
    "                             'dataset': 'Custom'})\n",
    "    # PATHS\n",
    "    dataset = args.dataset\n",
    "    mode = args.mode\n",
    "    code_path = os.path.dirname(os.getcwd()).replace(\"/registration\", \"\")\n",
    "    if not os.path.exists(os.path.join(code_path, \"logs\")):\n",
    "        os.mkdir(os.path.join(code_path, \"logs\"))\n",
    "    if not os.path.exists(os.path.join(code_path, \"weights\")):\n",
    "        os.mkdir(os.path.join(code_path, \"weights\"))\n",
    "    model_path = os.path.join(code_path, f\"weights/{dataset}_{mode}\")\n",
    "    logger = Logger(log_dir=os.path.join(code_path, f\"logs/{dataset}/\"), log_name=f\"{mode}\",\n",
    "                    reset_num_timesteps=True)\n",
    "\n",
    "    # TRAINING\n",
    "    agent = Agent().to(DEVICE)\n",
    "\n",
    "    if args.mode == \"pretrain\" and dataset == \"m40\":\n",
    "        print(f\"Training: dataset '{dataset}'  - mode '{args.mode}'\")\n",
    "        train(agent, logger, dataset, noise_type=\"clean\", epochs=50, lr=1e-3, lr_step=10, alpha=0,\n",
    "              model_path=model_path)\n",
    "    else:\n",
    "        if args.mode == \"il\":\n",
    "            alpha = 0.0\n",
    "            reward_mode = \"\"\n",
    "        elif args.mode == \"ilrl\":\n",
    "            alpha = 2.0 if dataset == \"m40\" else 0.1  # reduced influence on lm\n",
    "            reward_mode = \"step\"\n",
    "        else:\n",
    "            raise ValueError(\"No pretraining on LINEMOD. Use 'il' or 'ilrl' instead.\")\n",
    "        print(f\"Training: dataset '{dataset}' - mode '{args.mode}'{f' - alpha={alpha}' if args.mode != 'il' else ''}\")\n",
    "\n",
    "        if args.mode == \"pretrain\" and dataset == \"Custom\":\n",
    "            print(\"  loading pretrained weights...\")\n",
    "            if os.path.exists(os.path.join(code_path, f\"weights/Custom_pretrain.zip\")):\n",
    "                util_model.load(agent, os.path.join(code_path, f\"weights/Custom_pretrain.zip\"))\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"No pretrained weights found at \"\n",
    "                                        f\"{os.path.join(code_path, f'weights/Custom_pretrain.zip')}. Run with \"\n",
    "                                        f\"'pretrain' first or download the provided weights.\")\n",
    "\n",
    "        noise_type = \"jitter\" if dataset == \"Custom\" else \"segmentation\"\n",
    "        epochs = 50 if dataset == \"Custom\" else 100\n",
    "        lr = 1e-4 if dataset == \"Custom\" else 1e-3\n",
    "        lr_step = 10 if dataset == \"Custom\" else 20\n",
    "\n",
    "        train(agent, logger, dataset, noise_type, epochs=epochs, lr=lr, lr_step=lr_step,\n",
    "              alpha=alpha, reward_mode=reward_mode, model_path=model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccea02d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
