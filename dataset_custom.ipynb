{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3b45d7b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from torch.utils.data import Dataset\n",
    "import torchvision\n",
    "import os\n",
    "import h5py\n",
    "import pickle  # TODO or use h5py instead?\n",
    "import trimesh\n",
    "import open3d as o3d\n",
    "import glob\n",
    "\n",
    "import config as cfg\n",
    "import dataset.augmentation as Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0826a520",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    \n",
    "    def __init__(self, split, noise_type):\n",
    "        dataset_path = cfg.CUSTOM_PATH\n",
    "\n",
    "        self.samples, self.labels = self.get_samples(dataset_path, split)\n",
    "        self.transforms = self.get_transforms(split, noise_type)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples.shape[0]\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sample = {'points': self.samples[item, :, :], 'label': self.labels[item], 'idx': np.array(item, dtype=np.int32)}\n",
    "\n",
    "        if self.transforms:\n",
    "            sample = self.transforms(sample)\n",
    "        return sample\n",
    "\n",
    "    def get_transforms(self, split, noise_type):\n",
    "        # prepare augmentations\n",
    "        if noise_type == \"clean\":\n",
    "            # 1-1 correspondence for each point (resample first before splitting), no noise\n",
    "            if split == \"train\":\n",
    "                transforms = [Transforms.Resampler(2048),\n",
    "                              Transforms.SplitSourceRef(),\n",
    "                              Transforms.Scale(), Transforms.Shear(), Transforms.Mirror(),\n",
    "                              Transforms.RandomTransformSE3_euler(),\n",
    "                              Transforms.ShufflePoints()]\n",
    "            else:\n",
    "                transforms = [Transforms.SetDeterministic(),\n",
    "                              Transforms.FixedResampler(2048),\n",
    "                              Transforms.SplitSourceRef(),\n",
    "                              Transforms.RandomTransformSE3_euler(),\n",
    "                              Transforms.ShufflePoints()]\n",
    "        elif noise_type == \"jitter\":\n",
    "            # Points randomly sampled (might not have perfect correspondence), gaussian noise to position\n",
    "            if split == \"train\":\n",
    "                transforms = [Transforms.SplitSourceRef(),\n",
    "                              Transforms.Scale(), Transforms.Shear(), Transforms.Mirror(),\n",
    "                              Transforms.RandomTransformSE3_euler(),\n",
    "                              Transforms.Resampler(2048),\n",
    "                              Transforms.RandomJitter(),\n",
    "                              Transforms.ShufflePoints()]\n",
    "            else:\n",
    "                transforms = [Transforms.SetDeterministic(),\n",
    "                              Transforms.SplitSourceRef(),\n",
    "                              Transforms.RandomTransformSE3_euler(),\n",
    "                              Transforms.Resampler(2048),\n",
    "                              Transforms.RandomJitter(),\n",
    "                              Transforms.ShufflePoints()]\n",
    "        else:\n",
    "            raise ValueError(f\"Noise type {noise_type} not supported for CustomData.\")\n",
    "\n",
    "        return torchvision.transforms.Compose(transforms)\n",
    "\n",
    "    def get_samples(self, dataset_path, split):\n",
    "        if split == 'train':\n",
    "            path = os.path.join(dataset_path, 'train_data')\n",
    "        elif split == 'val':\n",
    "            path = os.path.join(dataset_path, 'val_data')\n",
    "        else:\n",
    "            path = os.path.join(dataset_path, 'test_data')\n",
    "            \n",
    "        all_data = []\n",
    "        all_labels = []\n",
    "        for item in glob.glob(path + '/*.obj'):\n",
    "            mesh = o3d.io.read_triangle_mesh(item)\n",
    "            pcd = mesh.sample_points_uniformly(number_of_points=2048)\n",
    "    \n",
    "            xyz = np.array(pcd.points)\n",
    "            data = xyz.astype(np.float32)\n",
    "            labels = 0\n",
    "\n",
    "            all_data.append(data)\n",
    "            all_labels.append(labels)\n",
    "\n",
    "        return np.array(all_data), np.array(all_labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "d6537f30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160\n",
      "{'label': 0, 'idx': array(0, dtype=int32), 'points_raw': array([[-0.34620836, -0.2937608 , -0.00196991],\n",
      "       [-0.43061003, -0.30287626,  0.0634876 ],\n",
      "       [-0.3337034 , -0.2682038 , -0.14593735],\n",
      "       ...,\n",
      "       [-0.15968841, -0.42347932,  0.09959693],\n",
      "       [-0.26971498, -0.44452402,  0.21975738],\n",
      "       [-0.32791668, -0.30645508,  0.08058053]], dtype=float32), 'points_src': array([[-0.03257793, -0.5947261 ,  0.32602638],\n",
      "       [ 0.2051293 , -0.6731661 ,  0.26315087],\n",
      "       [-0.1286774 , -0.5606637 , -0.25961742],\n",
      "       ...,\n",
      "       [-0.23216912, -0.74582636,  0.22245607],\n",
      "       [-0.02384359, -0.70644456,  0.38735688],\n",
      "       [ 0.13447371, -0.65190655,  0.12604025]], dtype=float32), 'points_ref': array([[-0.36624637, -0.30454427,  0.1120059 ],\n",
      "       [-0.34865776, -0.3240514 ,  0.16821665],\n",
      "       [-0.43703634, -0.3382782 ,  0.21494418],\n",
      "       ...,\n",
      "       [-0.22368574, -0.42774227,  0.13192919],\n",
      "       [-0.56998146, -0.22775926,  0.17650536],\n",
      "       [-0.34087044, -0.25995368, -0.0610512 ]], dtype=float32), 'scale': array([1.08854416, 0.85598511, 0.90022695]), 'transform_gt': array([[ 0.9259189 ,  0.1011199 , -0.3639355 , -0.33770552],\n",
      "       [-0.09008653,  0.9948142 ,  0.04721356,  0.2753309 ],\n",
      "       [ 0.36682245, -0.01093024,  0.93022674, -0.04289903]],\n",
      "      dtype=float32)}\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    dataset = CustomDataset(split = 'train', noise_type='clean')\n",
    "    print(len(dataset))\n",
    "    print(dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5f7e9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aa24e92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e92b784c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b15f6a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
